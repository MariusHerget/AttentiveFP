{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "if torch.cuda.is_available():\n",
    "    device_count = torch.cuda.device_count()\n",
    "    if device_count > 1:\n",
    "        print(f\"### multiple GPUs detected ({device_count})\")\n",
    "        best_device_id = -1\n",
    "        max_free_mem = 0\n",
    "        for i in range(device_count):\n",
    "            print(f\"### GPU {i} free memory: {torch.cuda.mem_get_info(i)[0]}\")\n",
    "            free, _ = torch.cuda.mem_get_info(i)\n",
    "            if free > max_free_mem:\n",
    "                max_free_mem = free\n",
    "                best_device_id = i\n",
    "        device = torch.device(f'cuda:{best_device_id}')\n",
    "        out_device = f\"GPU: cuda:{best_device_id}\"\n",
    "    else:\n",
    "        device = torch.device('cuda')\n",
    "        out_device = \"GPU: cuda:0\"\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    out_device = \"CPU\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_device(device)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.nn.Module.dump_patches = True\n",
    "\n",
    "print(\"########################\")\n",
    "print(\"Using device: \", out_device)\n",
    "print(\"########################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "# get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  2050\n",
      "not successfully processed smiles:  O=N([O-])C1=C(CN=C1NCCSCc2ncccc2)Cc3ccccc3\n",
      "not successfully processed smiles:  c1(nc(NC(N)=[NH2])sc1)CSCCNC(=[NH]C#N)NC\n",
      "not successfully processed smiles:  Cc1nc(sc1)\\[NH]=C(\\N)N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:08:53] Explicit valence for atom # 1 N, 4, is greater than permitted\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] Explicit valence for atom # 6 N, 4, is greater than permitted\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] Explicit valence for atom # 11 N, 4, is greater than permitted\n",
      "[22:08:53] Explicit valence for atom # 12 N, 4, is greater than permitted\n",
      "[22:08:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:08:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:08:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:08:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:08:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] Explicit valence for atom # 5 N, 4, is greater than permitted\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not successfully processed smiles:  s1cc(CSCCN\\C(NC)=[NH]\\C#N)nc1\\[NH]=C(\\N)N\n",
      "not successfully processed smiles:  c1c(c(ncc1)CSCCN\\C(=[NH]\\C#N)NCC)Br\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1ccccc1\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)NC(C)=O\n",
      "not successfully processed smiles:  n1c(csc1\\[NH]=C(\\N)N)c1cccc(c1)N\\C(NC)=[NH]\\C#N\n",
      "not successfully processed smiles:  s1cc(nc1\\[NH]=C(\\N)N)C\n",
      "not successfully processed smiles:  c1(cc(N\\C(=[NH]\\c2cccc(c2)CC)C)ccc1)CC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of successfully processed smiles:  2039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:53] WARNING: not removing hydrogen atom without neighbors\n",
      "/tmp/ipykernel_290847/1732648635.py:30: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "task_name = 'BBBP'\n",
    "tasks = ['BBBP']\n",
    "raw_filename = \"../data/BBBP.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "random_seed = 188\n",
    "random_seed = int(time.time())\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[22:08:54] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BBBP</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BBBP, smiles, cano_smiles]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<101]\n",
    "uncovered = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())>100]\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[~smiles_tasks_df[\"cano_smiles\"].isin(uncovered)]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "\n",
    "test_df = remained_df.sample(frac=1/10, random_state=random_seed) # test set\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/9, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649206\n",
      "atom_fc.weight torch.Size([150, 39])\n",
      "atom_fc.bias torch.Size([150])\n",
      "neighbor_fc.weight torch.Size([150, 49])\n",
      "neighbor_fc.bias torch.Size([150])\n",
      "GRUCell.0.weight_ih torch.Size([450, 150])\n",
      "GRUCell.0.weight_hh torch.Size([450, 150])\n",
      "GRUCell.0.bias_ih torch.Size([450])\n",
      "GRUCell.0.bias_hh torch.Size([450])\n",
      "GRUCell.1.weight_ih torch.Size([450, 150])\n",
      "GRUCell.1.weight_hh torch.Size([450, 150])\n",
      "GRUCell.1.bias_ih torch.Size([450])\n",
      "GRUCell.1.bias_hh torch.Size([450])\n",
      "GRUCell.2.weight_ih torch.Size([450, 150])\n",
      "GRUCell.2.weight_hh torch.Size([450, 150])\n",
      "GRUCell.2.bias_ih torch.Size([450])\n",
      "GRUCell.2.bias_hh torch.Size([450])\n",
      "align.0.weight torch.Size([1, 300])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 300])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 300])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([150, 150])\n",
      "attend.0.bias torch.Size([150])\n",
      "attend.1.weight torch.Size([150, 150])\n",
      "attend.1.bias torch.Size([150])\n",
      "attend.2.weight torch.Size([150, 150])\n",
      "attend.2.bias torch.Size([150])\n",
      "mol_GRUCell.weight_ih torch.Size([450, 150])\n",
      "mol_GRUCell.weight_hh torch.Size([450, 150])\n",
      "mol_GRUCell.bias_ih torch.Size([450])\n",
      "mol_GRUCell.bias_hh torch.Size([450])\n",
      "mol_align.weight torch.Size([1, 300])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([150, 150])\n",
      "mol_attend.bias torch.Size([150])\n",
      "output.weight torch.Size([2, 150])\n",
      "output.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.to(device)\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.tensor(x_atom),\n",
    "                                                 torch.tensor(x_bonds),\n",
    "                                                 torch.tensor(x_atom_index, dtype=torch.long),\n",
    "                                                 torch.tensor(x_bond_index, dtype=torch.long),\n",
    "                                                 torch.tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "\n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.tensor(validInds, dtype=torch.long).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.tensor(y_val_adjust, dtype=torch.long))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "\n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.tensor(x_atom),\n",
    "                                                 torch.tensor(x_bonds),\n",
    "                                                 torch.tensor(x_atom_index, dtype=torch.long),\n",
    "                                                 torch.tensor(x_bond_index, dtype=torch.long),\n",
    "                                                 torch.tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.tensor(validInds, dtype=torch.long).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.tensor(y_val_adjust, dtype=torch.long))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "\n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m best_param[\u001b[33m\"\u001b[39m\u001b[33mvalid_loss\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m9e8\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):    \n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     train_roc, train_prc, train_precision, train_recall, train_loss = \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = \u001b[38;5;28meval\u001b[39m(model, valid_df)\n\u001b[32m     10\u001b[39m     train_roc_mean = np.array(train_roc).mean()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(model, dataset)\u001b[39m\n\u001b[32m     54\u001b[39m smiles_list = batch_df.cano_smiles.values\n\u001b[32m     56\u001b[39m x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m atoms_prediction, mol_prediction = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_atom\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_bonds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_atom_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_bond_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     58\u001b[39m atom_pred = atoms_prediction.data[:,:,\u001b[32m1\u001b[39m].unsqueeze(\u001b[32m2\u001b[39m).cpu().numpy()\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i,task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tasks):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/lea/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/lea/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/lea/AttentiveFP/code/AttentiveFP/AttentiveLayers.py:36\u001b[39m, in \u001b[36mFingerprint.forward\u001b[39m\u001b[34m(self, atom_list, bond_list, atom_degree_list, bond_degree_list, atom_mask)\u001b[39m\n\u001b[32m     34\u001b[39m atom_mask = atom_mask.unsqueeze(\u001b[32m2\u001b[39m)\n\u001b[32m     35\u001b[39m batch_size,mol_length,num_atom_feat = atom_list.size()\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m atom_feature = F.leaky_relu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43matom_fc\u001b[49m\u001b[43m(\u001b[49m\u001b[43matom_list\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     38\u001b[39m bond_neighbor = [bond_list[i][bond_degree_list[i]] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_size)]\n\u001b[32m     39\u001b[39m bond_neighbor = torch.stack(bond_neighbor, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/lea/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/lea/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/lea/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/conda/envs/lea/lib/python3.12/site-packages/torch/utils/_device.py:106\u001b[39m, in \u001b[36mDeviceContext.__torch_function__\u001b[39m\u001b[34m(self, func, types, args, kwargs)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mdevice\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "\n",
    "#     tensorboard.add_scalars('ROC',{'train_roc':train_roc_mean,'valid_roc':valid_roc_mean},epoch)\n",
    "#     tensorboard.add_scalars('Losses',{'train_losses':train_loss,'valid_losses':valid_loss},epoch)\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.87:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "\n",
    "    train(model, train_df, optimizer, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_prc, test_precision, test_recall, test_losses = eval(best_model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd0031",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
